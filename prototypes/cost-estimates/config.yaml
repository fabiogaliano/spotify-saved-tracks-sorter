# Cost Estimation Configuration
# All costs in USD

defaults:
  track_count: 10000
  batch_sizes: [1, 10, 50, 100]
  sample_sizes: [25, 50, 100, 250, 500]
  track_presets: [1000, 10000, 50000, 100000, 500000]

providers:
  # ═══════════════════════════════════════════════════════════════════════════
  # VECTORIZATION / EMBEDDINGS
  # ═══════════════════════════════════════════════════════════════════════════

  - name: Replicate E5-Large
    type: vectorization
    provider: replicate
    model: saattrupdan/multilingual-e5-large-instruct
    cost_per_run: 0.00098
    avg_runtime_seconds: 1
    dimensions: 1024
    notes: "Multi-language text embedding, great for semantic search"

  - name: OpenAI text-embedding-3-small
    type: vectorization
    provider: openai
    model: text-embedding-3-small
    cost_per_1m_tokens: 0.02
    avg_tokens_per_song: 2000
    avg_runtime_seconds: 0.5
    dimensions: 1536
    batch_support: true
    max_batch_size: 2048
    notes: "Fast and cheap, good for most use cases"

  - name: OpenAI text-embedding-3-large
    type: vectorization
    provider: openai
    model: text-embedding-3-large
    cost_per_1m_tokens: 0.13
    avg_tokens_per_song: 2000
    avg_runtime_seconds: 0.5
    dimensions: 3072
    batch_support: true
    max_batch_size: 2048
    notes: "Higher quality, better for complex semantic tasks"

  - name: Voyage AI voyage-3
    type: vectorization
    provider: voyage
    model: voyage-3
    cost_per_1m_tokens: 0.06
    avg_tokens_per_song: 2000
    avg_runtime_seconds: 0.8
    dimensions: 1024
    batch_support: true
    max_batch_size: 128
    notes: "Excellent quality-to-cost ratio"

  - name: Cohere embed-v3
    type: vectorization
    provider: cohere
    model: embed-english-v3.0
    cost_per_1m_tokens: 0.10
    avg_tokens_per_song: 2000
    avg_runtime_seconds: 0.6
    dimensions: 1024
    batch_support: true
    max_batch_size: 96
    notes: "Strong multilingual support"

  # ═══════════════════════════════════════════════════════════════════════════
  # LLM ANALYSIS
  # ═══════════════════════════════════════════════════════════════════════════

  - name: GPT-4o-mini
    type: llm
    provider: openai
    model: gpt-4o-mini
    input_cost_per_1m_tokens: 0.15
    output_cost_per_1m_tokens: 0.60
    avg_input_tokens_per_song: 3000
    avg_output_tokens_per_song: 800
    avg_runtime_seconds: 2
    notes: "Best value for structured analysis"

  - name: GPT-4o
    type: llm
    provider: openai
    model: gpt-4o
    input_cost_per_1m_tokens: 2.50
    output_cost_per_1m_tokens: 10.00
    avg_input_tokens_per_song: 3000
    avg_output_tokens_per_song: 800
    avg_runtime_seconds: 3
    notes: "Higher quality analysis, 10x more expensive"

  - name: Claude Haiku 3.5
    type: llm
    provider: anthropic
    model: claude-3-5-haiku-latest
    input_cost_per_1m_tokens: 0.80
    output_cost_per_1m_tokens: 4.00
    avg_input_tokens_per_song: 3000
    avg_output_tokens_per_song: 800
    avg_runtime_seconds: 2
    notes: "Fast and capable, good for music analysis"

  - name: Claude Sonnet 4
    type: llm
    provider: anthropic
    model: claude-sonnet-4-20250514
    input_cost_per_1m_tokens: 3.00
    output_cost_per_1m_tokens: 15.00
    avg_input_tokens_per_song: 3000
    avg_output_tokens_per_song: 800
    avg_runtime_seconds: 4
    notes: "Best quality analysis, nuanced understanding"

  - name: Gemini 2.0 Flash
    type: llm
    provider: google
    model: gemini-2.0-flash
    input_cost_per_1m_tokens: 0.10
    output_cost_per_1m_tokens: 0.40
    avg_input_tokens_per_song: 3000
    avg_output_tokens_per_song: 800
    avg_runtime_seconds: 1.5
    notes: "Cheapest option, very fast"

  - name: Gemini 2.5 Pro
    type: llm
    provider: google
    model: gemini-2.5-pro-preview
    input_cost_per_1m_tokens: 1.25
    output_cost_per_1m_tokens: 10.00
    avg_input_tokens_per_song: 3000
    avg_output_tokens_per_song: 800
    avg_runtime_seconds: 3
    notes: "Advanced reasoning, good for complex analysis"

  - name: Llama 3.3 70B (Groq)
    type: llm
    provider: groq
    model: llama-3.3-70b-versatile
    input_cost_per_1m_tokens: 0.59
    output_cost_per_1m_tokens: 0.79
    avg_input_tokens_per_song: 3000
    avg_output_tokens_per_song: 800
    avg_runtime_seconds: 1
    notes: "Extremely fast inference via Groq"
